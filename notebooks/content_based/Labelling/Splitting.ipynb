{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting of tweets into xlsx-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to divide 520 tweets to eight xlsx-files, so that every tweet will be labelled by three persons. This means that each member of the group will get a excel-file that has 195 tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import re\n",
    "\n",
    "#Imports for encrypting\n",
    "import numpy as npv\n",
    "import base64\n",
    "\n",
    "from getpass import getpass\n",
    "from cryptography.fernet import Fernet\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads data from a file\n",
    "data_filepath = r'C:\\Users\\Inka\\Downloads\\kws_final_01-04-2020.json'\n",
    "\n",
    "data_arr = []\n",
    "column_names = ['id','text']\n",
    "with open(data_filepath, 'r') as f:\n",
    "    for tweet in f:\n",
    "        selected_row = []\n",
    "        json_tweet = json.loads(tweet)\n",
    "        try:\n",
    "            # filter out retweets and non-English tweets:\n",
    "            #Extended tweets\n",
    "            if not json_tweet['retweeted'] and 'RT @' not in json_tweet['text'] and json_tweet['lang'] == 'en' and json_tweet['extended_tweet'] != False: #has extended\n",
    "                tweet_id = json_tweet['id']\n",
    "                text = json_tweet['extended_tweet']['full_text']\n",
    "                new_list = [tweet_id, text]\n",
    "                data_arr.append(new_list)\n",
    "            #Not extended \n",
    "            elif not json_tweet['retweeted'] and 'RT @' not in json_tweet['text'] and json_tweet['lang'] == 'en':\n",
    "                print('x')\n",
    "                for col in column_names:\n",
    "                    selected_row.append(json_tweet[col])\n",
    "                data_arr.append(selected_row)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    data = pd.DataFrame(data_arr, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each 8 members labels 195 tweets.\n",
    "s = 520 #sample size\n",
    "n = 3 #the amount that each tweet is labelled\n",
    "p = 8 #number of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collects 520 random tweets for labelling from the final data\n",
    "data_set, label_set = train_test_split(data, test_size = s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_set)\n",
    "#Saves the original set:\n",
    "label_set.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Original_set.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = label_set['id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_crypto(password):\n",
    "    \"\"\"\n",
    "    Derives crypto key using the password and initializes the crypto library\n",
    "    that can be then called via encrypt and decrypt functions.\n",
    "    -----\n",
    "    Returns: cryptography.fernet.Fernet object\n",
    "    \"\"\"\n",
    "    password=password.encode()\n",
    "    salt = b'm\\xfffFvxfb\\xbexB\\x7f2\\xaa\\x1dj\\x8c\\x8f\\xf1\\\\{' \n",
    "    kdf = PBKDF2HMAC(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=salt,\n",
    "        iterations=100000,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "\n",
    "    return Fernet(base64.urlsafe_b64encode(kdf.derive(password)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_ids(ids, password):\n",
    "    \"\"\"\n",
    "    Encrypts a list of ids. Works on both strings and ints.\n",
    "    -----\n",
    "    Returns: list of bytes-typeobjects\n",
    "    \"\"\"\n",
    "    \n",
    "    crypto = initialize_crypto(password)\n",
    "    if isinstance(ids[0], int):\n",
    "        return [crypto.encrypt(bytes(str(ID), 'utf-8')) for ID in ids]\n",
    "    else:\n",
    "        return [crypto.encrypt(bytes(ID, 'utf-8')) for ID in ids] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_ids(encr_ids, password):\n",
    "    \"\"\"\n",
    "    Decrypts a list of bytes objects..\n",
    "    -----\n",
    "    Returns: list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    crypto = initialize_crypto(password)\n",
    "    keys = [crypto.decrypt(encr_ID).decode(\"utf-8\") for encr_ID in encr_ids] \n",
    "    try:\n",
    "        return [int(k) for k in keys]\n",
    "    except Exception as ex:\n",
    "        return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input password and encrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a passphrase > : \n",
      "路路路路路路路路\n"
     ]
    }
   ],
   "source": [
    "password = getpass(\"Please enter a passphrase > : \\n\")    # Reads what user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encrypt\n",
    "new_id_list = encrypt_ids(id_list, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decrypt\n",
    "T = decrypt_ids([b'gAAAAABehk1E1wAAecSppFGs_lw7HHq2_Ru0WKwDl-ZwQH-e2aC0DJbzYM6VH4wp1CS8U-K2_VU25sM0Bk_qOvviBkPiJbIqiBtk4-J6AjNe9BpMF8T3_gk='], password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1245335133659545605]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into xlsx-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = label_set.drop(columns=['id'])\n",
    "label_set = np.c_[new_id_list, label_set]\n",
    "label_set = pd.DataFrame(label_set, columns=['id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds extra column for labelling\n",
    "label_set[\"label\"] = \"\" #label_df\n",
    "\n",
    "#Splits the new_df into number of p dataframes:\n",
    "df_split = np.array_split(label_set, p)\n",
    "\n",
    "df1 = df_split[0].append([df_split[1], df_split[2]])\n",
    "df2 = df_split[1].append([df_split[2], df_split[3]])\n",
    "df3 = df_split[2].append([df_split[3], df_split[4]])\n",
    "df4 = df_split[3].append([df_split[4], df_split[5]])\n",
    "df5 = df_split[4].append([df_split[5], df_split[6]])\n",
    "df6 = df_split[5].append([df_split[6], df_split[7]])\n",
    "df7 = df_split[6].append([df_split[7], df_split[1]])\n",
    "df8 = df_split[7].append([df_split[1], df_split[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Inka.xlsx', index = False)\n",
    "df2.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Maria.xlsx', index = False)\n",
    "df3.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Ville.xlsx', index = False)\n",
    "df4.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Maryam.xlsx', index = False)\n",
    "df5.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Annika.xlsx', index = False)\n",
    "df6.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Veera.xlsx', index = False)\n",
    "df7.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Nuutti.xlsx', index = False)\n",
    "df8.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Estanislao.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's read the exels\n",
    "lb1 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Inka.xlsx')\n",
    "lb2 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Maria.xlsx')\n",
    "lb3 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Ville.xlsx')\n",
    "lb4 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Maryam.xlsx')\n",
    "lb5 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Annika.xlsx')\n",
    "lb6 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Veera.xlsx')\n",
    "lb7 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Nuutti.xlsx')\n",
    "lb8 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Estanislao.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b'gAAAAABehk1E1AgtNCoFyOt2S2_1z1FW30NViLQM15xd...</td>\n",
       "      <td>@StompyIsAwesome @CraigSJ Im not gonna argue ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b'gAAAAABehk1E-jOLZghyGHJHDucFIjGAe9rOLAKbVEJP...</td>\n",
       "      <td>\"It would be deeply ironic for [neoliberal] ad...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b'gAAAAABehk1EcNemYBpM20RU3eS2YS3nCvLRzBHd2bGT...</td>\n",
       "      <td>If only we could engineer similar hysteria ove...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b'gAAAAABehk1E95z41_KVRXYv43bkK2Ue3dnQzVBSTUxk...</td>\n",
       "      <td>@Carbazas_ Theyre recycling the same document...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b'gAAAAABehk1E1rHmsEzc3XkCrES7pUQky07uqYBhpjzh...</td>\n",
       "      <td>Time to start taking a daily multivitamin for ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  b'gAAAAABehk1E1AgtNCoFyOt2S2_1z1FW30NViLQM15xd...   \n",
       "1  b'gAAAAABehk1E-jOLZghyGHJHDucFIjGAe9rOLAKbVEJP...   \n",
       "2  b'gAAAAABehk1EcNemYBpM20RU3eS2YS3nCvLRzBHd2bGT...   \n",
       "3  b'gAAAAABehk1E95z41_KVRXYv43bkK2Ue3dnQzVBSTUxk...   \n",
       "4  b'gAAAAABehk1E1rHmsEzc3XkCrES7pUQky07uqYBhpjzh...   \n",
       "\n",
       "                                                text  label  \n",
       "0  @StompyIsAwesome @CraigSJ Im not gonna argue ...    NaN  \n",
       "1  \"It would be deeply ironic for [neoliberal] ad...    NaN  \n",
       "2  If only we could engineer similar hysteria ove...    NaN  \n",
       "3  @Carbazas_ Theyre recycling the same document...    NaN  \n",
       "4  Time to start taking a daily multivitamin for ...    NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the xlsx-files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines all the files together:\n",
    "combined = lb1.append([lb2, lb3, lb4, lb5, lb6, lb7, lb8])\n",
    "combined.reset_index(inplace=True)\n",
    "combined = combined.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b'gAAAAABehk1EcROeAH5VCAj58Uk7zRY-VLEkgNyZOS6l...</td>\n",
       "      <td>@szegfu_  I bet I love landscapes like thes...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b'gAAAAABehk1EA0dIPQ8Y5jenaZA19qEQ61fU892u6Pm3...</td>\n",
       "      <td>Nominations for the Environmental Leadership A...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b'gAAAAABehk1E00k3-d0QrYaJ6NP3rdqH22frBaT8u6Jj...</td>\n",
       "      <td>How can this be a win???\\nTrump's EPA chief cl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b'gAAAAABehk1E1t9KZA3VWqZWzU5dyOiGON0v8AAirIAz...</td>\n",
       "      <td>I'm starting to think when the worse effects o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b'gAAAAABehk1EiBelsO_d3bCm21IrpVCETCCAGZ9pfYkk...</td>\n",
       "      <td>@RahulGandhi My voice may not be heard but you...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1555</td>\n",
       "      <td>b'gAAAAABehk1EV_SMbiuiYvf_eKche0NKkU_5LSA2Qdtf...</td>\n",
       "      <td>Small collection of animal and bird photograph...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1556</td>\n",
       "      <td>b'gAAAAABehk1EhH5E5qZinExeg8NLmErM02WJxSnFoyE0...</td>\n",
       "      <td>You wont read a truer statement on Twitter to...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1557</td>\n",
       "      <td>b'gAAAAABehk1Eahli8Lj9cEUAOFOyZvnabed1NQobhVnp...</td>\n",
       "      <td>WATCH: The novel coronavirus is primarily pass...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1558</td>\n",
       "      <td>b'gAAAAABehk1ET-9Atsjd_O1uVYroun2GXHLRVyD_KvK2...</td>\n",
       "      <td>Here's the thing: I do not find what I am rese...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1559</td>\n",
       "      <td>b'gAAAAABehk1E4naQ5GWaFiiz19j55DiPNsIKDDFQs4Vf...</td>\n",
       "      <td>This is coming from someone that has incredibl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1560 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     b'gAAAAABehk1EcROeAH5VCAj58Uk7zRY-VLEkgNyZOS6l...   \n",
       "1     b'gAAAAABehk1EA0dIPQ8Y5jenaZA19qEQ61fU892u6Pm3...   \n",
       "2     b'gAAAAABehk1E00k3-d0QrYaJ6NP3rdqH22frBaT8u6Jj...   \n",
       "3     b'gAAAAABehk1E1t9KZA3VWqZWzU5dyOiGON0v8AAirIAz...   \n",
       "4     b'gAAAAABehk1EiBelsO_d3bCm21IrpVCETCCAGZ9pfYkk...   \n",
       "...                                                 ...   \n",
       "1555  b'gAAAAABehk1EV_SMbiuiYvf_eKche0NKkU_5LSA2Qdtf...   \n",
       "1556  b'gAAAAABehk1EhH5E5qZinExeg8NLmErM02WJxSnFoyE0...   \n",
       "1557  b'gAAAAABehk1Eahli8Lj9cEUAOFOyZvnabed1NQobhVnp...   \n",
       "1558  b'gAAAAABehk1ET-9Atsjd_O1uVYroun2GXHLRVyD_KvK2...   \n",
       "1559  b'gAAAAABehk1E4naQ5GWaFiiz19j55DiPNsIKDDFQs4Vf...   \n",
       "\n",
       "                                                   text  label  \n",
       "0     @szegfu_  I bet I love landscapes like thes...    NaN  \n",
       "1     Nominations for the Environmental Leadership A...    NaN  \n",
       "2     How can this be a win???\\nTrump's EPA chief cl...    NaN  \n",
       "3     I'm starting to think when the worse effects o...    NaN  \n",
       "4     @RahulGandhi My voice may not be heard but you...    NaN  \n",
       "...                                                 ...    ...  \n",
       "1555  Small collection of animal and bird photograph...    NaN  \n",
       "1556  You wont read a truer statement on Twitter to...    NaN  \n",
       "1557  WATCH: The novel coronavirus is primarily pass...    NaN  \n",
       "1558  Here's the thing: I do not find what I am rese...    NaN  \n",
       "1559  This is coming from someone that has incredibl...    NaN  \n",
       "\n",
       "[1560 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "label_list = []\n",
    "for i in range(s):\n",
    "\n",
    "    label1 = combined.iloc[i, 2]\n",
    "    label2 = combined.iloc[i + s, 2] \n",
    "    label3 = combined.iloc[i + s*2, 2]\n",
    "    \n",
    "    if label1 == label2:\n",
    "        label = label1\n",
    "        label_list.append(label)\n",
    "    elif label2 == label3:\n",
    "        label = label2\n",
    "        label_list.append(label)\n",
    "    elif label3 == label1:\n",
    "        label = label3\n",
    "        label_list.append(label)\n",
    "    else:\n",
    "        label = 'xxx'\n",
    "        label_list.append(label)\n",
    "        print(combined.iloc[i, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx', 'xxx']\n"
     ]
    }
   ],
   "source": [
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_set = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Original_set.xlsx')\n",
    "final_set = np.c_[orig_set, label_list]\n",
    "final_set = pd.DataFrame(final_set, columns=['id', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1245612731593441024</td>\n",
       "      <td>@szegfu_  I bet I love landscapes like thes...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1245425774481616896</td>\n",
       "      <td>Nominations for the Environmental Leadership A...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1245339442207804928</td>\n",
       "      <td>How can this be a win???\\nTrump's EPA chief cl...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1245560235458096896</td>\n",
       "      <td>I'm starting to think when the worse effects o...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1245439624089985024</td>\n",
       "      <td>@RahulGandhi My voice may not be heard but you...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>1245328820766274048</td>\n",
       "      <td>\"Trump has a kind of grip on the media where t...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>1245320066264116992</td>\n",
       "      <td>@ArvindKejriwal @PMOIndia @narendramodi As Loc...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517</td>\n",
       "      <td>1245374742900678912</td>\n",
       "      <td>#US one of the biggest donor, has dished out i...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>1245292978937253888</td>\n",
       "      <td>Thank you from Austria. Despite and because of...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>1245445042732445952</td>\n",
       "      <td>Millions of people = millions of bucket lists ...</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0    1245612731593441024  @szegfu_  I bet I love landscapes like thes...   \n",
       "1    1245425774481616896  Nominations for the Environmental Leadership A...   \n",
       "2    1245339442207804928  How can this be a win???\\nTrump's EPA chief cl...   \n",
       "3    1245560235458096896  I'm starting to think when the worse effects o...   \n",
       "4    1245439624089985024  @RahulGandhi My voice may not be heard but you...   \n",
       "..                   ...                                                ...   \n",
       "515  1245328820766274048  \"Trump has a kind of grip on the media where t...   \n",
       "516  1245320066264116992  @ArvindKejriwal @PMOIndia @narendramodi As Loc...   \n",
       "517  1245374742900678912  #US one of the biggest donor, has dished out i...   \n",
       "518  1245292978937253888  Thank you from Austria. Despite and because of...   \n",
       "519  1245445042732445952  Millions of people = millions of bucket lists ...   \n",
       "\n",
       "    label  \n",
       "0     xxx  \n",
       "1     xxx  \n",
       "2     xxx  \n",
       "3     xxx  \n",
       "4     xxx  \n",
       "..    ...  \n",
       "515   xxx  \n",
       "516   xxx  \n",
       "517   xxx  \n",
       "518   xxx  \n",
       "519   xxx  \n",
       "\n",
       "[520 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting of tweets into xlsx-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to divide 520 tweets to eight xlsx-files, so that every tweet will be labelled by three persons. This means that each member of the group will get a excel-file that has 195 tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import re\n",
    "\n",
    "#Imports for encrypting\n",
    "import numpy as npv\n",
    "import base64\n",
    "\n",
    "from getpass import getpass\n",
    "from cryptography.fernet import Fernet\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads data from a file\n",
    "data_filepath = r'C:\\Users\\Inka\\Downloads\\kws_final_01-04-2020.json'\n",
    "\n",
    "data_arr = []\n",
    "column_names = ['id_str','text']\n",
    "with open(data_filepath, 'r') as f:\n",
    "    for tweet in f:\n",
    "        selected_row = []\n",
    "        json_tweet = json.loads(tweet)\n",
    "            # filter out retweets and non-English tweets:\n",
    "            #Extended tweets\n",
    "        try:\n",
    "            if not json_tweet['retweeted'] and 'RT @' not in json_tweet['text'] and json_tweet['extended_tweet'] != False: #has extended\n",
    "                tweet_id = json_tweet['id_str']\n",
    "                text = json_tweet['extended_tweet']['full_text']\n",
    "                new_list = [tweet_id, text]\n",
    "                data_arr.append(new_list)\n",
    "                #Not extended \n",
    "        except: \n",
    "            if not json_tweet['retweeted'] and 'RT @' not in json_tweet['text']:\n",
    "                for col in column_names:\n",
    "                    selected_row.append(json_tweet[col])\n",
    "                data_arr.append(selected_row)\n",
    "\n",
    "    data = pd.DataFrame(data_arr, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Keywords.xlsx')\n",
    "keywords= keywords['keyword'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "for i in range(len(data)):\n",
    "    res = [ele for ele in keywords if(ele in data.iloc[i, 1])]\n",
    "    if bool(res) == True:\n",
    "        tweet_id = data.iloc[i, 0]\n",
    "        text = data.iloc[i, 1]\n",
    "        new_list = [tweet_id, text]\n",
    "        rows_list.append(new_list)\n",
    "        \n",
    "new_data = pd.DataFrame(rows_list, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each 8 members labels 195 tweets.\n",
    "s = 520 #sample size\n",
    "n = 3 #the amount that each tweet is labelled\n",
    "p = 8 #number of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collects 520 random tweets for labelling from the final data\n",
    "data_set, label_set = train_test_split(new_data, test_size = 520)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks how many same tweets the previous set contains with the new set\n",
    "og_set_1 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Original_set.xlsx')\n",
    "og_set_1\n",
    "\n",
    "count = 0\n",
    "for i in range(520):\n",
    "    for j in range(520):\n",
    "        if og_set_1.iloc[i, 1] == label_set.iloc[j, 1]:\n",
    "            print(label_set.iloc[j, 1])\n",
    "            print(og_set_1.iloc[i, 1])\n",
    "            count = count +1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_set)\n",
    "#Saves the original set:\n",
    "label_set.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Original_set_2.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = label_set['id_str'].tolist()\n",
    "id_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_crypto(password):\n",
    "    \"\"\"\n",
    "    Derives crypto key using the password and initializes the crypto library\n",
    "    that can be then called via encrypt and decrypt functions.\n",
    "    -----\n",
    "    Returns: cryptography.fernet.Fernet object\n",
    "    \"\"\"\n",
    "    password=password.encode()\n",
    "    salt = b'm\\xfffFvxfb\\xbexB\\x7f2\\xaa\\x1dj\\x8c\\x8f\\xf1\\\\{' \n",
    "    kdf = PBKDF2HMAC(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=salt,\n",
    "        iterations=100000,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "\n",
    "    return Fernet(base64.urlsafe_b64encode(kdf.derive(password)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_ids_base64(ids, password):\n",
    "    \"\"\"\n",
    "    Encrypts a list of ids. Works on both strings and ints.\n",
    "    -----\n",
    "    Returns: list of bytes-typeobjects\n",
    "    \"\"\"\n",
    "    \n",
    "    crypto = initialize_crypto(password)\n",
    "    #if isinstance(ids[0], int):\n",
    "    return [base64.urlsafe_b64encode(crypto.encrypt(bytes(str(ID), 'utf-8'))) for ID in ids]\n",
    "    #else:\n",
    "    #    return [base64.urlsafe_b64encode(crypto.encrypt(bytes(ID, 'utf-8'))) for ID in ids] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_ids_base64(encr_ids, password):\n",
    "    \"\"\"\n",
    "    Decrypts a list of bytes objects..\n",
    "    -----\n",
    "    Returns: list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    crypto = initialize_crypto(password)\n",
    "    keys = [crypto.decrypt(base64.b64decode(encr_ID.replace(\"b\\'\", '').replace(\"'\",\"\"))).decode(\"utf-8\")\n",
    "            for encr_ID in encr_ids] \n",
    "    #try:\n",
    "    #    return [int(k) for k in keys]\n",
    "    #except Exception as ex:\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert password and encrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass(\"Please enter a passphrase > : \\n\")    # Reads what user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encrypt\n",
    "new_id_list = encrypt_ids_base64(id_list, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list = lb1['id_str'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T64 = decrypt_ids_base64(list, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into xlsx-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changes id-column to encrypted version\n",
    "label_set = label_set.drop(columns=['id_str'])\n",
    "label_set = np.c_[new_id_list, label_set]\n",
    "label_set = pd.DataFrame(label_set, columns=['id_str', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds extra column for labelling\n",
    "label_set[\"label\"] = \"\" #label_df\n",
    "\n",
    "#Splits the new_df into number of p dataframes:\n",
    "df_split = np.array_split(label_set, p)\n",
    "\n",
    "df1 = df_split[0].append([df_split[1], df_split[2]])\n",
    "df2 = df_split[3].append([df_split[4], df_split[5]])\n",
    "df3 = df_split[6].append([df_split[7], df_split[0]])\n",
    "df4 = df_split[1].append([df_split[2], df_split[3]])\n",
    "df5 = df_split[4].append([df_split[5], df_split[6]])\n",
    "df6 = df_split[7].append([df_split[0], df_split[1]])\n",
    "df7 = df_split[2].append([df_split[3], df_split[4]])\n",
    "df8 = df_split[5].append([df_split[6], df_split[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Inka_2.xlsx', index = False)\n",
    "df2.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Maria_2.xlsx', index = False)\n",
    "df3.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Ville_2.xlsx', index = False)\n",
    "df4.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Maryam_2.xlsx', index = False)\n",
    "df5.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Annika_2.xlsx', index = False)\n",
    "df6.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Veera_2.xlsx', index = False)\n",
    "df7.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Nuutti_2.xlsx', index = False)\n",
    "df8.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Estanislao_2.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's read the exels\n",
    "lb1 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Inka_Finished.xlsx')\n",
    "lb2 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Maria_Finished.xlsx')\n",
    "lb3 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Ville_Finished.xlsx')\n",
    "lb4 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Maryam_Finished.xlsx')\n",
    "lb5 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Annika_Finished.xlsx')\n",
    "lb6 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Veera_Finished.xlsx')\n",
    "lb7 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Nuutti_Finished.xlsx')\n",
    "lb8 = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Labelling_Estanislao_Finished.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the xlsx-files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines all the files together:\n",
    "combined = lb1.append([lb2, lb3, lb4, lb5, lb6, lb7, lb8])\n",
    "combined.reset_index(inplace=True)\n",
    "combined = combined.drop(columns=['index']).drop(columns=['Unnamed: 3']).drop(columns=['Unnamed: 4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "count = 0\n",
    "\n",
    "for i in range(s):\n",
    "\n",
    "    label1 = combined.iloc[i, 1]\n",
    "    label2 = combined.iloc[i + s, 1] \n",
    "    label3 = combined.iloc[i + s*2, 1]\n",
    "    \n",
    "    if label1 == label2:\n",
    "        label = label1\n",
    "        label_list.append(label)\n",
    "    elif label2 == label3:\n",
    "        label = label2\n",
    "        label_list.append(label)\n",
    "    elif label3 == label1:\n",
    "        label = label3\n",
    "        label_list.append(label)\n",
    "    elif label1 != label2 and label2 != label3:\n",
    "        count = count + 1\n",
    "        print(combined.iloc[i, 2])\n",
    "        print('-------------------------------')\n",
    "        label = 4\n",
    "        label_list.append(label)\n",
    "    else:\n",
    "        label = 'xxx'\n",
    "        juu = juu + 1\n",
    "        label_list.append(label)\n",
    "        print(combined.iloc[i, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(label_list))\n",
    "\n",
    "numb1 = 0\n",
    "numb2 = 0\n",
    "numb3 = 0\n",
    "numb4 = 0\n",
    "\n",
    "for i in range(520):\n",
    "    if label_list[i] == 1:\n",
    "        numb1 = numb1 +1\n",
    "    elif label_list[i] == 2:\n",
    "        numb2 = numb2 +1\n",
    "    elif label_list[i] == 3:\n",
    "        numb3 = numb3 +1\n",
    "    elif label_list[i] == 4:\n",
    "        numb4 = numb4 +1\n",
    "    else:\n",
    "        numbx = numbx + 1\n",
    "        \n",
    "print(\"Label 1 amount:\", numb1/520*100, \"%\")\n",
    "print(\"Label 2 amount:\", numb2/520*100, \"%\")\n",
    "print(\"Label 3 amount:\", numb3/520*100, \"%\")\n",
    "print(\"Label 4 amount:\", numb4/520*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the labels with the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With original ids:\n",
    "#orig_set = pd.read_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Original_set.xlsx')\n",
    "#final_set = np.c_[orig_set, label_list]\n",
    "#final_set = pd.DataFrame(final_set, columns=['id', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_520 = combined.head(520)\n",
    "comb_520 = comb_520.drop(columns=['label'])\n",
    "\n",
    "final_set = np.c_[comb_520, label_list]\n",
    "final_set = pd.DataFrame(final_set, columns=['id_str', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_set.to_excel(r'C:\\Users\\Inka\\Desktop\\Koulu\\Project course\\Labelling\\Final_set.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

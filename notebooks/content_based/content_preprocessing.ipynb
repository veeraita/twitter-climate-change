{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%run \"../config.py\" # this imports variables from config.py as global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column_name = 'text'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ngram_range = (1, 2)\n",
    "min_df = 2 # cut-off value for ignoring rare words\n",
    "max_df = 1.0\n",
    "max_features = 300\n",
    "vectorizer = CountVectorizer(encoding='utf-8',\n",
    "                             ngram_range=ngram_range,\n",
    "                             stop_words=stop_words,\n",
    "                             max_df=max_df,\n",
    "                             min_df=min_df,\n",
    "                             max_features=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                               text\n",
      "0  1229818548740087809  my professor for my class on climate change li...\n",
      "1  1229818483191492608  Climate research by the rich #climatememe #cli...\n",
      "2  1229818231533309956  @wgg7wgg @pocphotocompany @DavidASeattle Sande...\n",
      "3  1229818181428170753  Inspired by Greta Thunberg, a 101-year-old cha...\n",
      "4  1229817872211378176  Here’s the best place to move if you’re worrie...\n",
      "5  1229817855283269633  Bezos’ climate pledge of $10 billion amounts t...\n",
      "6  1229817652513845248  Paddington Green: inside the anti-terror HQ ta...\n",
      "7  1229817515506851842  @WilHovaJr To say nothing of the fact that if ...\n",
      "8  1229817365703090176  Industrial #IoT: a silver bullet for climate c...\n",
      "9  1229817118146715649  How should Jeff Bezos invest his $10bn Earth F...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "if data_filepath.endswith('.json'):\n",
    "    data = pd.read_json(data_filepath, lines=True)\n",
    "elif data_filepath.endswith('.csv'):\n",
    "    data = pd.read_csv(data_filepath)\n",
    "print(data.head(10))\n",
    "tweets = data[text_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(item):\n",
    "    item = item.lower() # convert to lowercase\n",
    "    item = \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in item.split()]) # lemmatizing\n",
    "    item = item.replace('-', ' ') # replace dashes with whitespace\n",
    "    # remove numbers, punctuation, tags and URLs\n",
    "    item = re.sub(r'[^a-zA-Z ]+|(@[A-Za-z0-9]+)|http\\S+', '', item)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    my professor for my class on climate change li...\n",
       "1    climate research by the rich climatememe clima...\n",
       "2    wggwgg pocphotocompany davidaseattle sander be...\n",
       "3    inspire by greta thunberg a  year old champion...\n",
       "4    heres the best place to move if youre worried ...\n",
       "5    bezos climate pledge of  billion amount to nea...\n",
       "6    paddington green inside the anti terror hq tak...\n",
       "7    wilhovajr to say nothing of the fact that if b...\n",
       "8    industrial iot a silver bullet for climate cha...\n",
       "9    how should jeff bezos invest his bn earth fund...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_tweets = tweets.apply(preprocess)\n",
    "preprocessed_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advance',\n",
       " 'advance climate',\n",
       " 'ag',\n",
       " 'ag office',\n",
       " 'agenda',\n",
       " 'air',\n",
       " 'amazon',\n",
       " 'amp',\n",
       " 'analyses',\n",
       " 'anyway',\n",
       " 'become',\n",
       " 'best',\n",
       " 'bezos',\n",
       " 'bezos climate',\n",
       " 'bezos pledge',\n",
       " 'billion',\n",
       " 'billion fight',\n",
       " 'bloomberg',\n",
       " 'bloomberg program',\n",
       " 'business',\n",
       " 'care',\n",
       " 'carriept',\n",
       " 'carriept lisavanhoosept',\n",
       " 'cbarnespt',\n",
       " 'cbarnespt markmilligandpt',\n",
       " 'center',\n",
       " 'change',\n",
       " 'change agenda',\n",
       " 'chrishinzept',\n",
       " 'chrishinzept jhaleatx',\n",
       " 'climate',\n",
       " 'climate change',\n",
       " 'climate justice',\n",
       " 'climate pledge',\n",
       " 'climatechange',\n",
       " 'coal',\n",
       " 'come',\n",
       " 'commits',\n",
       " 'commits billion',\n",
       " 'current',\n",
       " 'current political',\n",
       " 'dawnmagnusson',\n",
       " 'dawnmagnusson drkaidpt',\n",
       " 'dont',\n",
       " 'drkaidpt',\n",
       " 'drkaidpt chrishinzept',\n",
       " 'economic',\n",
       " 'ecosearch',\n",
       " 'ecosearch news',\n",
       " 'environment',\n",
       " 'environment ecosearch',\n",
       " 'environmental',\n",
       " 'feel',\n",
       " 'fight',\n",
       " 'fight climate',\n",
       " 'focus',\n",
       " 'footprint',\n",
       " 'fuel',\n",
       " 'fund',\n",
       " 'generation',\n",
       " 'get',\n",
       " 'give',\n",
       " 'gun',\n",
       " 'heres',\n",
       " 'house',\n",
       " 'impact',\n",
       " 'important',\n",
       " 'inspire',\n",
       " 'jeff',\n",
       " 'jeff bezos',\n",
       " 'jhaleatx',\n",
       " 'jhaleatx sunsopeningband',\n",
       " 'justice',\n",
       " 'lawyer',\n",
       " 'lawyer ag',\n",
       " 'like',\n",
       " 'lisavanhoosept',\n",
       " 'lisavanhoosept rupalpt',\n",
       " 'literally',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'markmilligandpt',\n",
       " 'markmilligandpt mmitchellpcs',\n",
       " 'may',\n",
       " 'mmitchellpcs',\n",
       " 'need',\n",
       " 'news',\n",
       " 'news web',\n",
       " 'number',\n",
       " 'office',\n",
       " 'office advance',\n",
       " 'past',\n",
       " 'people',\n",
       " 'person',\n",
       " 'pledge',\n",
       " 'pledge billion',\n",
       " 'police',\n",
       " 'political',\n",
       " 'pollution',\n",
       " 'program',\n",
       " 'program reportedly',\n",
       " 'protect',\n",
       " 'put',\n",
       " 'put lawyer',\n",
       " 'raepru',\n",
       " 'raepru cbarnespt',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reportedly',\n",
       " 'reportedly put',\n",
       " 'research',\n",
       " 'rising',\n",
       " 'rupalpt',\n",
       " 'rupalpt dawnmagnusson',\n",
       " 'say',\n",
       " 'science',\n",
       " 'sea',\n",
       " 'see',\n",
       " 'something',\n",
       " 'still',\n",
       " 'sunsopeningband',\n",
       " 'sunsopeningband raepru',\n",
       " 'take',\n",
       " 'thats',\n",
       " 'thing',\n",
       " 'us',\n",
       " 'use',\n",
       " 'via',\n",
       " 'way',\n",
       " 'way climate',\n",
       " 'web',\n",
       " 'work',\n",
       " 'world',\n",
       " 'would',\n",
       " 'year',\n",
       " 'youre']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = vectorizer.fit_transform(preprocessed_tweets).toarray()\n",
    "vectorizer.get_feature_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

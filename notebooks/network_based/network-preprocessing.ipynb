{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network data pre-processing\n",
    "This notebook is a WIP, and will contain following sections:\n",
    "1. **Data inspection**\n",
    "2. **Data restructure**\n",
    "2. **Data selection**\n",
    "3. **Data transformation**\n",
    "4. **Data output**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Data inspection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = str(os.path.abspath(os.path.join('',\"../../data/toy_data/\")))\n",
    "data = pd.read_json(path + \"/data1.json\",orient=\"records\", dtype=False, lines=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>place_coordinates</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>user_geo_enabled</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>parent_tweet_id_str</th>\n",
       "      <th>parent_user_id_str</th>\n",
       "      <th>has_media</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-10 19:59:51+00:00</td>\n",
       "      <td>1182385272383791104</td>\n",
       "      <td>1182385272383791104</td>\n",
       "      <td>RT @JuliaHB1: FFS\\n\\nParalympic medallist Jame...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Pub</td>\n",
       "      <td>Sat Aug 09 16:04:21 +0000 2014</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1182278788333395968</td>\n",
       "      <td>459390022</td>\n",
       "      <td>False</td>\n",
       "      <td>[459390022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-10 19:59:51+00:00</td>\n",
       "      <td>1182385273738424321</td>\n",
       "      <td>1182385273738424321</td>\n",
       "      <td>RT @BasedPoland: More videos are emerging from...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>['Brazil']</td>\n",
       "      <td>#wwg1wga</td>\n",
       "      <td>Tue Feb 23 22:29:20 +0000 2010</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1182348104844156928</td>\n",
       "      <td>753974664041533440</td>\n",
       "      <td>False</td>\n",
       "      <td>[753974664041533440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-10 19:59:51+00:00</td>\n",
       "      <td>1182385274560634880</td>\n",
       "      <td>1182385274560634880</td>\n",
       "      <td>RT @pictoline: “Lo que está en movimiento es c...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>Mon Aug 08 14:17:45 +0000 2011</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1182370222847791105</td>\n",
       "      <td>3243658266</td>\n",
       "      <td>False</td>\n",
       "      <td>[3243658266]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-10 19:59:51+00:00</td>\n",
       "      <td>1182385274501894146</td>\n",
       "      <td>1182385274501894146</td>\n",
       "      <td>RT @350: “What we’re pushing to get back to ar...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>Milan, MI</td>\n",
       "      <td>Tue Oct 08 08:07:43 +0000 2019</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1180799866873810944</td>\n",
       "      <td>14266598</td>\n",
       "      <td>False</td>\n",
       "      <td>[14266598]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-10 19:59:51+00:00</td>\n",
       "      <td>1182385274720047109</td>\n",
       "      <td>1182385274720047109</td>\n",
       "      <td>RT @mollyfprince: I genuinely don’t understand...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>Pereira, Colombia</td>\n",
       "      <td>Wed Aug 07 15:07:39 +0000 2019</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1182288645753098243</td>\n",
       "      <td>911254908921298944</td>\n",
       "      <td>True</td>\n",
       "      <td>[911254908921298944, 1182248816105463809, 1182...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id               id_str  \\\n",
       "0 2019-10-10 19:59:51+00:00  1182385272383791104  1182385272383791104   \n",
       "1 2019-10-10 19:59:51+00:00  1182385273738424321  1182385273738424321   \n",
       "2 2019-10-10 19:59:51+00:00  1182385274560634880  1182385274560634880   \n",
       "3 2019-10-10 19:59:51+00:00  1182385274501894146  1182385274501894146   \n",
       "4 2019-10-10 19:59:51+00:00  1182385274720047109  1182385274720047109   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @JuliaHB1: FFS\\n\\nParalympic medallist Jame...   \n",
       "1  RT @BasedPoland: More videos are emerging from...   \n",
       "2  RT @pictoline: “Lo que está en movimiento es c...   \n",
       "3  RT @350: “What we’re pushing to get back to ar...   \n",
       "4  RT @mollyfprince: I genuinely don’t understand...   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "\n",
       "   in_reply_to_status_id in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0                    NaN                      None                  NaN   \n",
       "1                    NaN                      None                  NaN   \n",
       "2                    NaN                      None                  NaN   \n",
       "3                    NaN                      None                  NaN   \n",
       "4                    NaN                      None                  NaN   \n",
       "\n",
       "  in_reply_to_user_id_str  ... place_coordinates    hashtags  \\\n",
       "0                    None  ...              None          []   \n",
       "1                    None  ...              None  ['Brazil']   \n",
       "2                    None  ...              None          []   \n",
       "3                    None  ...              None          []   \n",
       "4                    None  ...              None          []   \n",
       "\n",
       "       user_location                 user_created_at user_geo_enabled  \\\n",
       "0            The Pub  Sat Aug 09 16:04:21 +0000 2014            False   \n",
       "1           #wwg1wga  Tue Feb 23 22:29:20 +0000 2010             True   \n",
       "2          Guatemala  Mon Aug 08 14:17:45 +0000 2011             True   \n",
       "3          Milan, MI  Tue Oct 08 08:07:43 +0000 2019            False   \n",
       "4  Pereira, Colombia  Wed Aug 07 15:07:39 +0000 2019            False   \n",
       "\n",
       "  is_retweet  parent_tweet_id_str  parent_user_id_str  has_media  \\\n",
       "0          1  1182278788333395968           459390022      False   \n",
       "1          1  1182348104844156928  753974664041533440      False   \n",
       "2          1  1182370222847791105          3243658266      False   \n",
       "3          1  1180799866873810944            14266598      False   \n",
       "4          1  1182288645753098243  911254908921298944       True   \n",
       "\n",
       "                                            mentions  \n",
       "0                                        [459390022]  \n",
       "1                               [753974664041533440]  \n",
       "2                                       [3243658266]  \n",
       "3                                         [14266598]  \n",
       "4  [911254908921298944, 1182248816105463809, 1182...  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 36)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at                   datetime64[ns, UTC]\n",
       "id                                         int64\n",
       "id_str                                    object\n",
       "text                                      object\n",
       "source                                    object\n",
       "truncated                                   bool\n",
       "in_reply_to_status_id                    float64\n",
       "in_reply_to_status_id_str                 object\n",
       "in_reply_to_user_id                      float64\n",
       "in_reply_to_user_id_str                   object\n",
       "in_reply_to_screen_name                   object\n",
       "user                                      object\n",
       "geo                                       object\n",
       "coordinates                               object\n",
       "place                                     object\n",
       "contributors                              object\n",
       "retweeted_status                          object\n",
       "is_quote_status                             bool\n",
       "quote_count                                int64\n",
       "reply_count                                int64\n",
       "retweet_count                              int64\n",
       "favorite_count                             int64\n",
       "entities                                  object\n",
       "favorited                                   bool\n",
       "retweeted                                   bool\n",
       "possibly_sensitive                        object\n",
       "filter_level                              object\n",
       "lang                                      object\n",
       "timestamp_ms                      datetime64[ns]\n",
       "extended_entities                         object\n",
       "quoted_status_id                         float64\n",
       "quoted_status_id_str                      object\n",
       "quoted_status                             object\n",
       "quoted_status_permalink                   object\n",
       "display_text_range                        object\n",
       "extended_tweet                            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id_str'] = data['id_str'].astype(str)\n",
    "data['in_reply_to_user_id_str'] = data['in_reply_to_user_id_str'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Data Restructuring**\n",
    "#### Reducing complexity / flattening data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user_id_str']           = [row['id_str'] for row in data['user']]\n",
    "data['user_name']             = [row['name'] for row in data['user']]\n",
    "data['user_screen_name']      = [row['screen_name'] for row in data['user']]\n",
    "data['user_defined_location'] = [row['location'] if pd.notnull(row['location']) else None for row in data['user']]\n",
    "data['user_followers_count']  = [row['followers_count'] for row in data['user']]\n",
    "data['place_country_code']    = [row['country_code'] if row != None else None for row in data['place']]\n",
    "data['place_name']            = [row['name'] if row != None else None for row in data['place']]\n",
    "data['place_type']            = [row['place_type'] if row != None else None for row in data['place']]\n",
    "data['place_coordinates']     = [dict(row['bounding_box'])['coordinates'][0][0] if row != None else None for row in data['place']]\n",
    "data['hashtags']              = [[htags['text'].lower() for htags in row['hashtags']] for row in data['entities'] if row['hashtags'] != \"\"]\n",
    "data['user_location']         = [row['location'] for row in data['user']]\n",
    "data['user_created_at']       = [row['created_at'] for row in data['user']]\n",
    "data['user_geo_enabled']      = [row['geo_enabled'] for row in data['user']]\n",
    "data['is_retweet']            = [1 if b else 0 for b in data['retweeted_status'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting parent tweet ids and user ids for retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_tweet_ids = []\n",
    "parent_user_ids  = []\n",
    "for index, row in data.iterrows():\n",
    "    if row['is_retweet']:\n",
    "        tweet = row['retweeted_status']\n",
    "        parent_tweet_ids.append(tweet['id_str'])\n",
    "        parent_user_ids.append(tweet['user']['id_str'])\n",
    "    else:\n",
    "        parent_tweet_ids.append(None)\n",
    "        parent_user_ids.append(None)\n",
    "        \n",
    "data['parent_tweet_id_str'] = parent_tweet_ids\n",
    "data['parent_user_id_str']  = parent_user_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting boolean value for original video / image content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['has_media'] = pd.notna(data['extended_entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract ids of the mentioned users for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mentions(x):\n",
    "    return [str(n.replace(\"id': \",\"\")) for n in re.findall(\"id': [0-9]*\", str(x))]\n",
    "\n",
    "data['mentions'] = data['entities'].apply(lambda x: extract_mentions(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(x):\n",
    "    return [n.replace(\"'text': \",\"\") for n in re.findall(\"'text': '[a-zA-Z0-9_]*'\", str(x))]\n",
    "\n",
    "data['hashtags'] = data['entities'].apply(lambda x: extract_hashtags(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Data selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geolocation data\n",
    "Quick look at the location data (Twitter's page about geotagging available [here](https://developer.twitter.com/en/docs/tutorials/filtering-tweets-by-location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet-level location data:\n",
      "\t* Coordinates present in 2 (1.0 %) of the tweets\n",
      "\t* Place type present in 2 (1.0 %) of the tweets\n",
      "\t* Place name present in 2 (1.0 %) of the tweets\n",
      "\t* Country code present in 2 (1.0 %) of the tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"Tweet-level location data:\") \n",
    "print(\"\\t* Coordinates present in {0} ({1} %) of the tweets\".format(\n",
    "                                np.sum(data['place_coordinates'].notnull()) , \n",
    "                                np.sum(data['place_coordinates'].notnull()) / data.shape[0] * 100))\n",
    "\n",
    "print(\"\\t* Place type present in {0} ({1} %) of the tweets\".format(\n",
    "                                np.sum(data['place_type'].notnull()), \n",
    "                                np.sum(data['place_type'].notnull()) / data.shape[0] * 100))\n",
    "\n",
    "print(\"\\t* Place name present in {0} ({1} %) of the tweets\".format(\n",
    "                                np.sum(data['place_name'].notnull()), \n",
    "                                np.sum(data['place_name'].notnull()) / data.shape[0] * 100))\n",
    "\n",
    "print(\"\\t* Country code present in {0} ({1} %) of the tweets\".format(\n",
    "                                np.sum(data['place_country_code'].notnull()), \n",
    "                                np.sum(data['place_country_code'].notnull()) / data.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-level location data present in 137 (68.5 %) of the tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"User-level location data present in {} ({} %) of the tweets\".format(\n",
    "                                    np.sum(data['user_location'].notna()), \n",
    "                                    np.sum(data['user_location'].notna() / data.shape[0] * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                               The Pub\n",
       "1                                              #wwg1wga\n",
       "2                                             Guatemala\n",
       "3                                             Milan, MI\n",
       "4                                     Pereira, Colombia\n",
       "5                                             Smethwick\n",
       "6                                            Texas, USA\n",
       "8                                               Wroclaw\n",
       "10                                  Charlottesville, VA\n",
       "13                                        New York, USA\n",
       "15                                  South East, England\n",
       "16    Mi’kma’ki, the ancestral and #unceded territor...\n",
       "19                           frigiliana (Malaga) ESPAÑA\n",
       "20                                           Denver, CO\n",
       "21                                            Barcelona\n",
       "23                                               Canada\n",
       "26                                      Goiânia, Brasil\n",
       "28                                                  Xix\n",
       "29                                                  USA\n",
       "31                                       Poznań, Polska\n",
       "Name: user_location, dtype: object"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preview:\")\n",
    "user_locs = data['user_location'][data['user_location'].notna()]\n",
    "user_locs[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the set membership of the entries in a set of English country names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = set([e[0] for e in pd.read_csv('countries.csv', index_col=0).values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([loc in all_countries for loc in user_locs.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this initial preview, the tweet-level location data is sparse and the user-defined location data is unstructured and ambiguous. \n",
    "#### Dropping out unnecessary attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = ['created_at',                                  # Timestamp for possible time comparisons\n",
    "             'id_str',                                      # Id of the tweet for collecting replies / retweets\n",
    "             'hashtags',                                    # Hashtags for coloring the nodes\n",
    "             'user_id_str',                                 # Identify / define nodes in the network \n",
    "             'mentions',                                    # Define interaction-edges for mentions\n",
    "             'parent_tweet_id_str',\n",
    "             'parent_user_id_str',                          # Retweets\n",
    "             'place_coordinates','place_name','place_type',\n",
    "             'user_defined_location',                       # Keep location/place data for filtering by city \n",
    "             'in_reply_to_user_id_str']                     # Define interaction-edges for replies\n",
    "data_sel  = data[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 12)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>mentions</th>\n",
       "      <th>parent_tweet_id_str</th>\n",
       "      <th>parent_user_id_str</th>\n",
       "      <th>place_coordinates</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>user_defined_location</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385288850620416</td>\n",
       "      <td>[]</td>\n",
       "      <td>1114171414230241281</td>\n",
       "      <td>[47753979]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>47753979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385288993222665</td>\n",
       "      <td>['wtylewizji']</td>\n",
       "      <td>826731067172335616</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Poznań, Polska</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385289374982144</td>\n",
       "      <td>['Rom']</td>\n",
       "      <td>871823728145039361</td>\n",
       "      <td>[22926365, 1006419421244678144]</td>\n",
       "      <td>1181194087891968001</td>\n",
       "      <td>22926365</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ludwigshafen am Rhein, Germany</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385289383292930</td>\n",
       "      <td>[]</td>\n",
       "      <td>1125031585726849025</td>\n",
       "      <td>[1156281409193086976, 16465385]</td>\n",
       "      <td>1182300609833254918</td>\n",
       "      <td>1156281409193086976</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385289530097665</td>\n",
       "      <td>[]</td>\n",
       "      <td>69903520</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[-76.712759, 44.16054]</td>\n",
       "      <td>Kingston</td>\n",
       "      <td>city</td>\n",
       "      <td>Pluto America</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385289806745600</td>\n",
       "      <td>[]</td>\n",
       "      <td>536068379</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Victoria, Australia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385290016677888</td>\n",
       "      <td>[]</td>\n",
       "      <td>1358892625</td>\n",
       "      <td>[6134882, 1177946826407849987, 118237722104814...</td>\n",
       "      <td>1182377221048143872</td>\n",
       "      <td>6134882</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Vienna, Austria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385290029215745</td>\n",
       "      <td>[]</td>\n",
       "      <td>20725516</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>West Yorks via North London</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385290209480704</td>\n",
       "      <td>[]</td>\n",
       "      <td>965014538130083840</td>\n",
       "      <td>[1653217514]</td>\n",
       "      <td>1182372429122936843</td>\n",
       "      <td>1653217514</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-10-10 19:59:55+00:00</td>\n",
       "      <td>1182385290423558144</td>\n",
       "      <td>[]</td>\n",
       "      <td>1481735839</td>\n",
       "      <td>[212973087]</td>\n",
       "      <td>1180756871248060416</td>\n",
       "      <td>212973087</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at               id_str        hashtags  \\\n",
       "30 2019-10-10 19:59:55+00:00  1182385288850620416              []   \n",
       "31 2019-10-10 19:59:55+00:00  1182385288993222665  ['wtylewizji']   \n",
       "32 2019-10-10 19:59:55+00:00  1182385289374982144         ['Rom']   \n",
       "33 2019-10-10 19:59:55+00:00  1182385289383292930              []   \n",
       "34 2019-10-10 19:59:55+00:00  1182385289530097665              []   \n",
       "35 2019-10-10 19:59:55+00:00  1182385289806745600              []   \n",
       "36 2019-10-10 19:59:55+00:00  1182385290016677888              []   \n",
       "37 2019-10-10 19:59:55+00:00  1182385290029215745              []   \n",
       "38 2019-10-10 19:59:55+00:00  1182385290209480704              []   \n",
       "39 2019-10-10 19:59:55+00:00  1182385290423558144              []   \n",
       "\n",
       "            user_id_str                                           mentions  \\\n",
       "30  1114171414230241281                                         [47753979]   \n",
       "31   826731067172335616                                                 []   \n",
       "32   871823728145039361                    [22926365, 1006419421244678144]   \n",
       "33  1125031585726849025                    [1156281409193086976, 16465385]   \n",
       "34             69903520                                                 []   \n",
       "35            536068379                                                 []   \n",
       "36           1358892625  [6134882, 1177946826407849987, 118237722104814...   \n",
       "37             20725516                                                 []   \n",
       "38   965014538130083840                                       [1653217514]   \n",
       "39           1481735839                                        [212973087]   \n",
       "\n",
       "    parent_tweet_id_str   parent_user_id_str       place_coordinates  \\\n",
       "30                 None                 None                    None   \n",
       "31                 None                 None                    None   \n",
       "32  1181194087891968001             22926365                    None   \n",
       "33  1182300609833254918  1156281409193086976                    None   \n",
       "34                 None                 None  [-76.712759, 44.16054]   \n",
       "35                 None                 None                    None   \n",
       "36  1182377221048143872              6134882                    None   \n",
       "37                 None                 None                    None   \n",
       "38  1182372429122936843           1653217514                    None   \n",
       "39  1180756871248060416            212973087                    None   \n",
       "\n",
       "   place_name place_type           user_defined_location  \\\n",
       "30       None       None                            None   \n",
       "31       None       None                  Poznań, Polska   \n",
       "32       None       None  Ludwigshafen am Rhein, Germany   \n",
       "33       None       None                            None   \n",
       "34   Kingston       city                  Pluto America    \n",
       "35       None       None             Victoria, Australia   \n",
       "36       None       None                 Vienna, Austria   \n",
       "37       None       None     West Yorks via North London   \n",
       "38       None       None                            None   \n",
       "39       None       None                            None   \n",
       "\n",
       "   in_reply_to_user_id_str  \n",
       "30                47753979  \n",
       "31                    None  \n",
       "32                    None  \n",
       "33                    None  \n",
       "34                    None  \n",
       "35                    None  \n",
       "36                    None  \n",
       "37                    None  \n",
       "38                    None  \n",
       "39                    None  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 30\n",
    "k = 10\n",
    "data_sel.iloc[n:n+k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Data transformation** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodes\n",
    "Let's transform the node data so that we will have a set of unique node ids attached to most relevant node attributes. We select only location as the node attribute. This enables us flexible filtering of data based on location during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = dict(data[['user_id_str','user_defined_location']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edges\n",
    "Let's define a method for transforming the data into a list of edges with edge attributes. For this we will conveniency class Counter from collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_edge(src,trg,edges):\n",
    "    if (str(src),str(trg)) not in edges: edges[(src,trg)] = Counter({'orig_mentions':0, 'retweets':0, 'replies':0})            \n",
    "\n",
    "def transform_to_edges(data: pd.DataFrame) -> dict:\n",
    "    edges = {} # Dict where keys are tuples containing the source and target ids\n",
    "               # values are Counters with attributes: orig_mentions, retweets, replies\n",
    "    \n",
    "    for i,row in data.iterrows():\n",
    "        src      = row['user_id_str']\n",
    "        par_id   = row['parent_user_id_str']\n",
    "        reply_id = row['in_reply_to_user_id_str'] \n",
    "        mentions = list(row['mentions'])\n",
    "        \n",
    "        # Note that mentions are superset of retweets and replies, thus we \n",
    "        # first remove both of them, and then authentic mentions left.\n",
    "        \n",
    "        # Case 1. replies\n",
    "        if reply_id in mentions:\n",
    "            init_edge(src,reply_id,edges)\n",
    "            edges[(src,reply_id)]['replies'] += 1\n",
    "            mentions.remove(reply_id)\n",
    "        \n",
    "        # Case 2. retweets\n",
    "        if par_id is not None:\n",
    "            init_edge(src,par_id,edges)\n",
    "            edges[(src,par_id)]['retweets'] += 1\n",
    "            mentions.remove(par_id) \n",
    "            \n",
    "        # Case 3. mentions\n",
    "        for trg in mentions:\n",
    "            init_edge(src,trg,edges)\n",
    "            edges[(src,trg)]['orig_mentions'] += 1            \n",
    "        \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 edges found in the data set.\n"
     ]
    }
   ],
   "source": [
    "edges = transform_to_edges(data_sel)\n",
    "print(len(edges), 'edges found in the data set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the resulting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 Index 110\n",
      "replies:  0\n",
      "retweets: 1\n",
      "mentions: 0\n",
      "\n",
      "\n",
      "111 Index 111\n",
      "replies:  0\n",
      "retweets: 1\n",
      "mentions: 0\n",
      "\n",
      "\n",
      "112 Index 112\n",
      "replies:  0\n",
      "retweets: 1\n",
      "mentions: 0\n",
      "\n",
      "\n",
      "113 Index 113\n",
      "replies:  0\n",
      "retweets: 1\n",
      "mentions: 0\n",
      "\n",
      "\n",
      "114 Index 114\n",
      "replies:  1\n",
      "retweets: 0\n",
      "mentions: 0\n",
      "\n",
      "\n",
      "115 Index 115\n",
      "replies:  0\n",
      "retweets: 1\n",
      "mentions: 0\n",
      "\n",
      "\n",
      "116 Index 116\n",
      "replies:  1\n",
      "retweets: 0\n",
      "mentions: 0\n",
      "\n",
      "\n",
      "117 Index 117\n",
      "replies:  0\n",
      "retweets: 0\n",
      "mentions: 1\n",
      "\n",
      "\n",
      "118 Index 118\n",
      "replies:  0\n",
      "retweets: 0\n",
      "mentions: 1\n",
      "\n",
      "\n",
      "119 Index 119\n",
      "replies:  0\n",
      "retweets: 0\n",
      "mentions: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k, rang = 110, 120\n",
    "items = list(edges.items())\n",
    "for i in range(k,rang):\n",
    "    print(i,'Index {0}\\nreplies:  {1}\\nretweets: {2}\\nmentions: {3}\\n\\n'.format(i,items[i][1]['replies'], items[i][1]['retweets'], items[i][1]['orig_mentions']))\n",
    "    if k == rang: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Data Output** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = [(i[0],i[1],dict(k)) for i,k in edges.items()]\n",
    "missing_tweets = list(out_retweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nodelist.json', 'w') as file:\n",
    "    json.dump(nodes, file, allow_nan=False)\n",
    "    \n",
    "with open('edgelist.json', 'w') as file:\n",
    "    json.dump(edgelist, file, allow_nan=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aalto-sci-project",
   "language": "python",
   "name": "aalto-sci-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
